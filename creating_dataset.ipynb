{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Dataset\n",
    "\n",
    "This notebook is about creating a network train dataset with input <code>[eta,deta,dphi,theta,qop,pt,phi,z0,dz0,do,dhadpt,q,n]</code> and lebel efficiency<br>\n",
    "The code is about creating a tensor contains tensor contain input e.g. <code>[input1,input2,...]</code> and tensor with lebel <code>[eff1,eff2,....]</code><br>\n",
    "Then choose some of the data in the tensor to be the test dataset and the rest train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import lib needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "# ref main.ipynb\n",
    "\n",
    "data = np.load(\"testevals/data_10k.npz\")\n",
    "\n",
    "# Convert the data from dumpy arrays to pytorch tensors\n",
    "data = {k: torch.from_numpy(v) for k, v in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 0.8571, 0.8000,  ..., 1.0000, 1.0000, 1.0000])\n",
      "tensor([0.6250, 0.8571, 0.8889,  ..., 1.0000, 1.0000, 1.0000])\n",
      "tensor([1.0000, 1.0000, 0.9000,  ..., 1.0000, 1.0000, 1.0000])\n",
      "tensor([0.5556, 0.4375, 0.5556,  ..., 0.7500, 1.0000, 1.0000])\n",
      "tensor([1.0000, 0.8571, 0.8000,  ..., 1.0000, 1.0000, 1.0000])\n",
      "tensor([0.7143, 0.7500, 0.7273,  ..., 1.0000, 1.0000, 1.0000])\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.])\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# ref plot.py\n",
    "from metrics import calc_match_scores\n",
    "\n",
    "def calc_scores(reco_method,match_thresh = 0.75):\n",
    "    match_metric = \"tmp\"\n",
    "\n",
    "    pred_pix_valid = data[f\"{reco_method}_pix_valid\"]\n",
    "    pred_sct_valid = data[f\"{reco_method}_sct_valid\"]\n",
    "    pred_valid = data[f\"{reco_method}_valid\"]\n",
    "\n",
    "    true_pix_valid = data[\"sudo_pix_valid\"]\n",
    "    true_sct_valid = data[\"sudo_sct_valid\"]\n",
    "    true_valid = data[\"sudo_valid\"]\n",
    "\n",
    "    match_score = calc_match_scores(pred_pix_valid, pred_sct_valid, pred_valid, true_pix_valid, true_sct_valid, true_valid, match_metric)\n",
    "    matches = match_score  >= match_thresh\n",
    "\n",
    "    true_has_match = matches.any(1) & true_valid\n",
    "    pred_has_match = matches.any(2) & pred_valid\n",
    "        \n",
    "    true_num = true_valid.sum(-1)\n",
    "    pred_num = pred_valid.sum(-1)\n",
    "        \n",
    "    true_num_matched = true_has_match.sum(-1)\n",
    "    pred_num_matched = pred_has_match.sum(-1)\n",
    "\n",
    "    roi_eff = true_num_matched / true_num # matched num / true num\n",
    "    roi_pur = pred_num_matched / pred_num # matched num / predicted num\n",
    "    print(roi_eff)\n",
    "    print(roi_pur)\n",
    "    return pred_has_match , roi_eff, roi_pur\n",
    "\n",
    "pred_pred_has_match, pred_roi_eff, pred_roi_pur = calc_scores(\"pred\")\n",
    "sisp_pred_has_match, sisp_roi_eff, sisp_roi_pur = calc_scores(\"sisp\")\n",
    "reco_pred_has_match, reco_roi_eff, reco_roi_pur = calc_scores(\"reco\")\n",
    "sudo_pred_has_match, sudo_roi_eff, sudo_roi_pur = calc_scores(\"sudo\")\n",
    "\n",
    "pred_has_match = {\"pred\":pred_pred_has_match,\"sisp\":sisp_pred_has_match,\"reco\":reco_pred_has_match,\"sudo\":sudo_pred_has_match}\n",
    "roi_pur = {\"pred\":pred_roi_pur,\"sisp\":sisp_roi_pur,\"reco\":reco_roi_pur,\"sudo\":sudo_roi_pur}\n",
    "roi_eff = {\"pred\":pred_roi_eff,\"sisp\":sisp_roi_eff,\"reco\":reco_roi_eff,\"sudo\":sudo_roi_eff}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_quanity(qtys = \"deta\"):\n",
    "    matched_reco = torch.tensor([])\n",
    "    unmatched_reco = torch.tensor([])\n",
    "\n",
    "    for idx in range(pred_has_match[\"pred\"].shape[0]):\n",
    "        #print(pred_has_match[\"pred\"][idx] )\n",
    "        #print(data[\"pred_valid\"][idx])\n",
    "        matched_reco = torch.cat((matched_reco,data[f\"sudo_{qtys}\"][idx][pred_has_match[\"pred\"][idx] & data[\"pred_valid\"][idx]]),0)\n",
    "        unmatched_reco = torch.cat((unmatched_reco,data[f\"sudo_{qtys}\"][idx][~pred_has_match[\"pred\"][idx] & data[\"pred_valid\"][idx]]),0)\n",
    "    \n",
    "    return matched_reco, unmatched_reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0037, -0.0037,  0.0046,  ..., -0.0452, -0.0272,  0.0388])\n",
      "torch.Size([60438])\n",
      "tensor([0.0000, 0.0000, 0.0000,  ..., 0.0002, 0.0000, 0.0000])\n",
      "torch.Size([9874])\n"
     ]
    }
   ],
   "source": [
    "# Test the funciton\n",
    "matched_data, unmatched_data = calculate_quanity()\n",
    "print(matched_data)\n",
    "print(matched_data.shape)\n",
    "print(unmatched_data)\n",
    "print(unmatched_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of hits of reconstructed tracks\n",
    "def calculate_hits():\n",
    "    hit_matched = torch.tensor([])\n",
    "    hit_unmatched = torch.tensor([])\n",
    "    for idx in range(pred_has_match[\"pred\"].shape[0]):\n",
    "        for idx2 in range(data[\"pred_valid\"][idx].shape[0]):\n",
    "            if data[\"pred_valid\"][idx][idx2]:\n",
    "                #print(pred_has_match[\"pred\"][idx][idx2])\n",
    "                if pred_has_match[\"pred\"][idx][idx2]:\n",
    "                    #print(data[\"sudo_pix_valid\"][idx][idx2])\n",
    "                    hit = torch.tensor([data[\"pred_pix_valid\"][idx][idx2].count_nonzero()+data[\"pred_sct_valid\"][idx][idx2].count_nonzero()])\n",
    "                    hit_matched = torch.cat((hit_matched,hit),dim=0)\n",
    "                else:\n",
    "                    hit = torch.tensor([data[\"pred_pix_valid\"][idx][idx2].count_nonzero()+data[\"pred_sct_valid\"][idx][idx2].count_nonzero()])\n",
    "                    hit_unmatched = torch.cat((hit_unmatched,hit),dim=0)\n",
    "                    #print(hit)\n",
    "    #print(hit_matched)\n",
    "    #print(hit_matched.shape)\n",
    "    #print(hit_unmatched)\n",
    "    #print(hit_unmatched.shape)\n",
    "    return hit_matched, hit_unmatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([13., 12., 12.,  ..., 13., 12., 11.]),\n",
       " tensor([12., 11., 12.,  ...,  7.,  2., 10.]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_hits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems we have 60438 matched track and 9874 unmatched track<br>\n",
    "I choose first 3k matched track and first 500 unmatched data as my test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_good = 3000 # let first 3k of the good reco track be test set\n",
    "num_test_bad = 500 # let first 500 of the bad reco track be test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantity = [\"pt\",\"eta\",\"deta\",\"phi\",\"dphi\",\"theta\",\"z0\",\"dz0\",\"d0\",\"q\",\"qop\",\"bhadpt\"]\n",
    "\n",
    "data_test_label = torch.cat((torch.tensor([1,0]).repeat(num_test_good,1),torch.tensor([0,1]).repeat(num_test_bad,1)),dim = 0)\n",
    "data_train_label_good_reco = torch.tensor([1,0]).repeat(matched_data.shape[0]-num_test_good,1)\n",
    "data_train_label_bad_reco = torch.tensor([0,1]).repeat(unmatched_data.shape[0]-num_test_bad,1)\n",
    "data_train_label = torch.cat([data_train_label_good_reco,data_train_label_bad_reco],dim = 0)\n",
    "#data_test_input = torch.cat((hit_matched[0:3000],hit_unmatched[0:300]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_matched, hit_unmatched = calculate_hits()\n",
    "pt_matched , pt_unmatched = calculate_quanity(\"pt\")\n",
    "eta_matched , eta_unmatched = calculate_quanity(\"eta\")\n",
    "deta_matched , deta_unmatched = calculate_quanity(\"deta\")\n",
    "phi_matched , phi_unmatched = calculate_quanity(\"phi\")\n",
    "dphi_matched , dphi_unmatched = calculate_quanity(\"dphi\")\n",
    "theta_matched , theta_unmatched = calculate_quanity(\"theta\")\n",
    "z0_matched , z0_unmatched = calculate_quanity(\"z0\")\n",
    "dz0_matched , dz0_unmatched = calculate_quanity(\"dz0\")\n",
    "d0_matched , d0_unmatched = calculate_quanity(\"d0\")\n",
    "q_matched , q_unmatched = calculate_quanity(\"q\")\n",
    "qop_matched , qop_unmatched = calculate_quanity(\"qop\")\n",
    "bhadpt_matched , bhadpt_unmatched = calculate_quanity(\"bhadpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3500, 7])\n"
     ]
    }
   ],
   "source": [
    "data_test_input = torch.tensor([])\n",
    "for i in range(num_test_good):\n",
    "    data_test_input = torch.cat((data_test_input,torch.tensor([[hit_matched[i]/18,\n",
    "                                 pt_matched[i]/2.e5,\n",
    "                                 0.5 + eta_matched[i]/5,\n",
    "                                 0.5 + deta_matched[i]/0.1,\n",
    "                                 #phi_matched[i],\n",
    "                                 0.5 + dphi_matched[i]/0.1,\n",
    "                                 theta_matched[i]/np.pi,\n",
    "                                 #z0_matched[i],\n",
    "                                 #dz0_matched[i],\n",
    "                                 #d0_matched[i],\n",
    "                                 #q_matched[i],\n",
    "                                 0.5 + qop_matched[i]/1,\n",
    "                                 #bhadpt_matched[i],\n",
    "                                 ]])),dim = 0)\n",
    "for i in range(num_test_bad):\n",
    "    data_test_input = torch.cat((data_test_input,torch.tensor([[hit_unmatched[i]/18,\n",
    "                                 pt_unmatched[i]/2.e5,\n",
    "                                 0.5 + eta_unmatched[i]/5,\n",
    "                                 0.5 + deta_unmatched[i]/0.1,\n",
    "                                 #phi_unmatched[i],\n",
    "                                 0.5 + dphi_unmatched[i]/0.1,\n",
    "                                 theta_unmatched[i]/np.pi,\n",
    "                                 #z0_unmatched[i],\n",
    "                                 #dz0_unmatched[i],\n",
    "                                 #d0_unmatched[i],\n",
    "                                 #q_unmatched[i],\n",
    "                                 0.5 + qop_unmatched[i]/1,\n",
    "                                 #bhadpt_unmatched[i],\n",
    "                                 ]])),dim = 0)\n",
    "print(data_test_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([66812, 7])\n"
     ]
    }
   ],
   "source": [
    "data_train_input = torch.tensor([])\n",
    "for i in range(num_test_good,matched_data.shape[0]):\n",
    "    data_train_input = torch.cat((data_train_input,torch.tensor([[hit_matched[i]/18,\n",
    "                                 pt_matched[i]/2.e5,\n",
    "                                 0.5 + eta_matched[i]/5,\n",
    "                                 0.5 + deta_matched[i]/0.1,\n",
    "                                 #phi_matched[i],\n",
    "                                 0.5 + dphi_matched[i]/0.1,\n",
    "                                 theta_matched[i]/np.pi,\n",
    "                                 #z0_matched[i],\n",
    "                                 #dz0_matched[i],\n",
    "                                 #d0_matched[i],\n",
    "                                 #q_matched[i],\n",
    "                                 0.5 + qop_matched[i]/1,\n",
    "                                 #bhadpt_matched[i],\n",
    "                                 ]])),dim = 0)\n",
    "for i in range(num_test_bad,unmatched_data.shape[0]):\n",
    "    data_train_input = torch.cat((data_train_input,torch.tensor([[hit_unmatched[i]/18,\n",
    "                                 pt_unmatched[i]/2.e5,\n",
    "                                 0.5 + eta_unmatched[i]/5,\n",
    "                                 0.5 + deta_unmatched[i]/0.1,\n",
    "                                 #phi_unmatched[i],\n",
    "                                 0.5 + dphi_unmatched[i]/0.1,\n",
    "                                 theta_unmatched[i]/np.pi,\n",
    "                                 #z0_unmatched[i],\n",
    "                                 #dz0_unmatched[i],\n",
    "                                 #d0_unmatched[i],\n",
    "                                 #q_unmatched[i],\n",
    "                                 0.5 + qop_unmatched[i]/1,\n",
    "                                 #bhadpt_unmatched[i],\n",
    "                                 ]])),dim = 0)\n",
    "print(data_train_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset input(good) size = torch.Size([66812, 7])\n",
      "Train dataset label(good) size = torch.Size([66812, 2])\n",
      "Test dataset input size = torch.Size([3500, 7])\n",
      "Test dataset label size = torch.Size([3500, 2])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train dataset input(good) size = {data_train_input.shape}\")\n",
    "print(f\"Train dataset label(good) size = {data_train_label.shape}\")\n",
    "print(f\"Test dataset input size = {data_test_input.shape}\")\n",
    "print(f\"Test dataset label size = {data_test_label.shape}\")\n",
    "\n",
    "folder = \"75_dataset\"\n",
    "try:\n",
    "    os.makedirs(f\"data/{folder}\")\n",
    "except:\n",
    "    print(\"Path already created\")\n",
    "torch.save(data_train_input,f\"data/{folder}/data_train_input.csv\")\n",
    "torch.save(data_train_label,f\"data/{folder}/data_train_label.csv\")\n",
    "torch.save(data_test_input,f\"data/{folder}/data_test_input.csv\")\n",
    "torch.save(data_test_label,f\"data/{folder}/data_test_label.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
